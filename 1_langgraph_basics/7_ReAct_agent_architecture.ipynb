{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54e46eb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_community.tools import ArxivQueryRun, WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper, ArxivAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b28794",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "api_wrapper_arxiv=ArxivAPIWrapper(\n",
    "    top_k_results=2,\n",
    "    doc_content_chars_max=250\n",
    ")\n",
    "arxiv = ArxivQueryRun(api_wrapper=api_wrapper_arxiv)\n",
    "print(arxiv.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4838e87f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "arxiv.invoke(\"Attention is all you need!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3380b43a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "api_wrapper_wiki=WikipediaAPIWrapper(\n",
    "    top_k_results=1,\n",
    "    doc_content_chars_max=500\n",
    ")\n",
    "wiki = ArxivQueryRun(api_wrapper=api_wrapper_wiki)\n",
    "print(wiki.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b940c091",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "wiki.invoke(\"What is machine learning!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98586c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"]=os.getenv(\"TAVILY_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_v2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=\"ReAct-agent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a820b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"Divide a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a / b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb86908",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [arxiv, wiki, tavily, add, divide, multiply]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4056ea49",
   "metadata": {},
   "outputs": [],
   "source": [
    "## initialize llm model\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm=ChatGroq(model=\"qwen-2.5-32b\")\n",
    "\n",
    "llm_with_tools=llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73802f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "llm_with_tools.invoke([HumanMessage(content=\"What is the recent AI news\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6500ce0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools.invoke([HumanMessage(content=\"What is the recent AI news\")]).tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3a6d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "### State Schema\n",
    "from typing_extension import TypedDict\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf6dd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Entire chatbot with LangGraph\n",
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "### Node definition\n",
    "def tool_calling_llm(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "### Build graph\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "builder.add_conditional_edges(\n",
    "    \"tool_calling_llm\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is not a tool call -> ools_condition routes to END\n",
    "    tools_condition\n",
    ")\n",
    "builder.add_edge(\"tools\", \"tool_calling_llm\") # <- This what ReAct agent architecture\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f53f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = graph.invoke(\n",
    "    {\"messages\": HumanMessage(content=\"What is attention is all you need, Add 3 plus 3 and then mutiply 10\")}\n",
    ")\n",
    "\n",
    "for m in messages['messages']:\n",
    "    m.pretty_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae4e372",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
